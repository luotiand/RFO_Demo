import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import os
import subprocess
from script.plot import plot_2d_results, plot_results, hinton, plot_3d_compare_with_diff
from rectified.rectified_flow import RectFlow
import time
import matplotlib.pyplot as plt
from script.dataset import MyDataset_ns, darcyDataset
from torch.utils.data import DataLoader
from rectified_flow.scorenet.scorenet2d import FNO2d
import argparse
import logging
from Adam import Adam

torch.set_default_dtype(torch.float32)
torch.backends.cudnn.benchmark = True


################################################################
# 改进的损失函数
################################################################
class LpLoss(object):
    def __init__(self, p=2, reduction='mean'):
        super(LpLoss, self).__init__()
        self.p = p
        self.reduction = reduction

    def rel(self, x, y):
        num_examples = x.size(0)
        x_flat = x.view(num_examples, -1)
        y_flat = y.view(num_examples, -1)
        
        diff_norm = torch.norm(x_flat - y_flat, p=self.p, dim=1)
        y_norm = torch.norm(y_flat, p=self.p, dim=1)
        y_norm_safe = torch.where(y_norm < 1e-10, torch.ones_like(y_norm) * 1e-10, y_norm)
        
        rel_error = diff_norm / y_norm_safe
        
        if self.reduction == 'mean':
            return torch.mean(rel_error)
        elif self.reduction == 'sum':
            return torch.sum(rel_error)
        return rel_error

    def abs(self, x, y):
        num_examples = x.size(0)
        x_flat = x.view(num_examples, -1)
        y_flat = y.view(num_examples, -1)
        diff_norm = torch.norm(x_flat - y_flat, p=self.p, dim=1)
        
        if self.reduction == 'mean':
            return torch.mean(diff_norm)
        elif self.reduction == 'sum':
            return torch.sum(diff_norm)
        return diff_norm

    def __call__(self, x, y, mode='rel'):
        if mode == 'abs':
            return self.abs(x, y)
        else:
            return self.rel(x, y)


################################################################
# 评估指标计算（仅保留L2相对误差用于绘图）
################################################################
def calculate_metrics(pred, true):
    with torch.no_grad():
        # 只计算L2相对误差（用于评估）
        lp_loss = LpLoss(p=2, reduction='mean')
        l2_rel = lp_loss(pred, true, mode='rel')
        return l2_rel.item()


################################################################
# 日志配置
################################################################
def setup_logger(save_path):
    if not os.path.exists(save_path):
        os.makedirs(save_path)
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(os.path.join(save_path, 'training.log')),
            logging.StreamHandler()
        ]
    )


################################################################
# 主函数
################################################################
def main(config):
    device = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")
    if not torch.cuda.is_available():
        logging.warning("No GPU available, using CPU")
    
    save_path = config['save_path']
    para_path = config['para_path']
    setup_logger(save_path)
    logging.info(f"Initializing training on device: {device}")
    
    # 核心参数
    niter = config['niter']
    batch_size = config['batch_size']
    lr = config['lr']
    T = config['T']
    rf_dt = config['rf_dt']
    train = config['train']
    scorenet_model_class = config['scorenet_model_class']
    model_name = config['model_name']
    rf = config['rf']
    target_len = config['target_len']
    
    ################################################################
    # 数据加载与标准化
    ################################################################
    train_dataset = darcyDataset('/data5/store1/dlt/rectified_flow/data/piececonst_r421_N1024_smooth1.mat', mode='train',target_size=target_len)
    test_dataset = darcyDataset('/data5/store1/dlt/rectified_flow/data/piececonst_r421_N1024_smooth2.mat', mode='test',target_size=target_len)
    
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=0,
        pin_memory=True,
        drop_last=True
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=True,
        drop_last=True
    )
    logging.info(f"Training dataset size: {len(train_dataset)}, Test dataset size: {len(test_dataset)}")
    
    # 计算标准化参数
    a_all, x_all = [], []
    for a_batch, x_batch in train_loader:
        a_all.append(a_batch)
        x_all.append(x_batch)
    a_all = torch.cat(a_all, dim=0)
    x_all = torch.cat(x_all, dim=0)
    
    a_mean, a_std = a_all.mean(), a_all.std() + 1e-6
    x_mean, x_std = x_all.mean(), x_all.std() + 1e-6
    logging.info(f"标准化参数 - a: (mean={a_mean:.6f}, std={a_std:.6f}); x: (mean={x_mean:.6f}, std={x_std:.6f})")
    
    ################################################################
    # 模型初始化
    ################################################################
    scorenet_model = globals()[scorenet_model_class]()
    scorenet_model = scorenet_model.to(device)
    score_net = scorenet_model
    logging.info(f"Model initialized: {scorenet_model_class} on {device}")
    
    # 测试集数据初始化
    sample_a, sample_x = test_dataset.get_full_data()
    a = (sample_a.to(device) - a_mean) / a_std
    x = (sample_x.to(device) - x_mean) / x_std
    logging.info(f"Test data loaded - a shape: {a.shape}, x shape: {x.shape}")
    
    ################################################################
    # 训练流程
    ################################################################
    if train:
        optimizer = Adam(score_net.parameters(), lr=lr, weight_decay=1e-4)
        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)
        criterion = LpLoss(p=2, reduction='mean')
        
        # 仅记录L2相关指标
        train_losses = []  # 训练L2相对损失
        test_l2rel_list = []  # 测试L2相对误差
        check_interval = max(1, niter // 10)
        
        start_time = time.time()
        logging.info(f"开始训练 - 总迭代次数: {niter}, 批次大小: {batch_size}")
        
        for epoch in range(niter):
            score_net.train()
            train_loss = 0.0
            t1 = time.time()
            
            for a_batch, x_batch in train_loader:
                a_ = (a_batch.to(device) - a_mean) / a_std
                x_ = (x_batch.to(device) - x_mean) / x_std
                
                time_options = torch.tensor([0.0,1.0], device=device, dtype=torch.float32)  # 定义可选时间值
                rand_indices = torch.randint(0, 2, (batch_size, 1), device=device)  # 生成0-2的随机索引
                t = time_options[rand_indices]  # 根据索引选取时间值（形状：(current_bs, 1)）
                t = t.view(batch_size, *([1] * (len(a_.shape) - 1)))
                t = t.repeat(1, len(a_[0]), len(a_[0]))
                
                optimizer.zero_grad()
                xt_ = rf.straight_process(a_, x_, t)
                exact_score = x_ - a_
                pred_score = score_net(xt_, t)
                # import ipdb;ipdb.set_trace()
                loss = criterion(pred_score, exact_score)
                train_loss += loss.item()
                
                loss.backward()
                optimizer.step()
                
                del a_, x_, t, xt_, exact_score, pred_score
                torch.cuda.empty_cache()
            
            avg_train_loss = train_loss / len(train_loader)
            train_losses.append(avg_train_loss)
            scheduler.step()
            
            # 评估
            if (epoch + 1) % check_interval == 0 or epoch == niter - 1:
                score_net.eval()
                with torch.no_grad():
                    xt = [a]
                    for t_val in np.arange(0.0, T, rf_dt):
                        t_tensor = torch.ones(len(a), 1, 1,device=device) * t_val
                        t_tensor = t_tensor.repeat(1, len(a[0]),len(a[0]))
                        score = score_net(xt[-1], t_tensor)
                        xt_ = rf.forward_process(xt[-1], score, dt=rf_dt)
                        xt.append(xt_)
                    
                    xt_last = xt[-1] * x_std + x_mean
                    x_true = x * x_std + x_mean
                    l2_rel = calculate_metrics(xt_last, x_true)  # 仅L2相对误差
                    
                    test_l2rel_list.append(l2_rel)
                    logging.info(
                        f"Epoch {epoch+1}/{niter} - "
                        f"Train Loss: {avg_train_loss:.6f}, "
                        f"Test L2 Rel: {l2_rel:.6f}"
                    )
                score_net.train()
            
            # 进度日志
            if (epoch + 1) % 5 == 0:
                t2 = time.time()
                epoch_time = t2 - t1
                remaining_time = (niter - epoch - 1) * (t2 - start_time) / (epoch + 1)
                logging.info(
                    f"Epoch {epoch+1} - "
                    f"Train Loss: {avg_train_loss:.6f}, "
                    f"Time: {epoch_time:.2f}s, "
                    f"Estimated Remaining: {remaining_time/60:.2f}min"
                )
        
        # 保存模型（保持原始路径和名称）
        torch.save(score_net.state_dict(), f"{para_path}{model_name}")
        logging.info(f"模型保存至: {para_path}{model_name}")
        
        # 绘制训练曲线（仅保留L2相关曲线）
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)
        # 训练损失曲线
        ax1.plot(range(1, niter+1), train_losses, 'b-', label='Train L2 Relative Loss')
        ax1.set_ylabel("Loss", fontsize=12)
        ax1.set_yscale("log")
        ax1.set_title("Training Loss", fontsize=14)
        ax1.legend()
        ax1.grid(True)
        
        # 测试L2相对误差曲线（移除MAPE）
        ax2.plot(
            np.arange(check_interval, niter+1, check_interval) if niter != check_interval else [niter],
            test_l2rel_list, 'g-s', label='Test L2 Relative Error'
        )
        ax2.set_xlabel("Epoch", fontsize=12)
        ax2.set_ylabel("Error", fontsize=12)
        ax2.set_title("Test L2 Relative Error", fontsize=14)  # 标题仅保留L2
        ax2.legend()
        ax2.grid(True)
        
        # 保存训练曲线（保持原始命名风格）
        plt.savefig(f"{save_path}{scorenet_model_class.lower()}_{target_len}_training_metrics.png", dpi=300)
        plt.close()
    
    ################################################################
    # 推理与评估
    ################################################################
    score_net.load_state_dict(torch.load(f"{para_path}{model_name}", map_location=device))
    score_net.eval()
    logging.info("开始推理评估...")
    
    with torch.no_grad():
        # 正向推理
        xt = [a]
        for t_val in np.arange(0.0, T, rf_dt):
            t_tensor = torch.ones(len(xt[0]), 1, 1,device=device) * t_val
            t_tensor = t_tensor.repeat(1, len(a[0]),len(a[0]))
            score = score_net(xt[-1], t_tensor)
            xt_ = rf.forward_process(xt[-1], score, dt=rf_dt)
            xt.append(xt_)
        
        # 反向推理
        yt = [x]
        for t_val in np.arange(0.0, T, rf_dt):
            t_tensor = torch.ones(len(yt[0]), 1, 1,device=device) * t_val
            t_tensor = t_tensor.repeat(1, len(a[0]),len(a[0]))
            score = score_net(yt[-1], T - t_tensor)
            yt_ = rf.reverse_process(yt[-1], score, dt=rf_dt)
            yt.append(yt_)
        
        # 还原数据
        xt_last = xt[-1] * x_std + x_mean
        x_true = x * x_std + x_mean
        yt_last = yt[-1] * a_std + a_mean
        threshold = (3 + 12) / 2  # 结果为 7.5

        # 2. 对 yt_last 进行阈值化处理：
        #    - 小于阈值 7.5 的值设为 3
        #    - 大于等于阈值 7.5 的值设为 12
        # （用 torch.tensor 确保设备和数据类型与 yt_last 一致，避免报错）
        yt_last = torch.where(
            yt_last < threshold,  # 条件：小于阈值
            torch.tensor(3.0, device=yt_last.device, dtype=yt_last.dtype),  # 满足条件时赋值 3
            torch.tensor(12.0, device=yt_last.device, dtype=yt_last.dtype)  # 不满足条件时赋值 12
        )
        y_true = a * a_std + a_mean
        tolerance = 1e-6  # 容差（根据实际数据精度调整）
        match_mask = torch.isclose(yt_last, y_true, atol=tolerance)  # 逐元素匹配（带容差）

        # 计算分类准确率 = 匹配元素个数 / 总元素个数（总分辨率像素数）
        total_pixels = yt_last.numel()  # 总元素个数（即分辨率：如s×s，对应85×85、141×141等）
        matched_pixels = match_mask.sum().item()  # 匹配的元素个数
        classification_acc = matched_pixels / total_pixels  # 分类准确率（0~1之间）
        # 计算最终指标（仅L2）
        final_l2rel = calculate_metrics(xt_last, x_true)
        final_l2rel2 = calculate_metrics(yt_last, y_true)
        logging.info(f"最终评估 - L2 Relative Error: {final_l2rel:.6f}")
        logging.info(f"最终评估 - L2 Relative Error: {final_l2rel2:.6f}")
        logging.info(f"最终评估 - 分类准确率: {classification_acc:.6f}")
        # 绘图（保持原始命名）
        plot_2d_results(
            data1=x_true,
            data2=xt_last,
            labels=['Ground Truth','Prediction'],
            base_filename=f'{save_path}{scorenet_model_class.lower()}_{target_len}_operator_learning_1d'
        )
        plot_2d_results(
            data1=y_true,
            data2=yt_last,
            labels=['Ground Truth','Prediction'],
            base_filename=f'{save_path}{scorenet_model_class.lower()}_{target_len}_reverse_learning_1d'
        )


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('config', type=str, help='Path to configuration file')
    args = parser.parse_args()
    
    config = {}
    with open(args.config, 'r') as f:
        exec(f.read(), config)
    
    main(config)